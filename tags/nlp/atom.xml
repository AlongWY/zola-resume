<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
	<title>Feng - NLP</title>
	<subtitle>A clean resume theme</subtitle>
	<link href="https://resume.alongwy.top/tags/nlp/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="https://resume.alongwy.top"/>
	<generator uri="https://www.getzola.org/">Zola</generator>
	<updated>2021-08-28T14:13:14.674+00:00</updated>
	<id>https://resume.alongwy.top/tags/nlp/atom.xml</id>
	<entry xml:lang="en">
		<title>Huggingface&#x2F;datasets</title>
		<published>2021-08-28T14:13:14.674+00:00</published>
		<updated>2021-08-28T14:13:14.674+00:00</updated>
		<link href="https://resume.alongwy.top/opensource/huggingface-datasets/" type="text/html"/>
		<id>https://resume.alongwy.top/opensource/huggingface-datasets/</id>
		<content type="html">&lt;p&gt;ü§ó Datasets is a lightweight library providing two main features:&lt;&#x2F;p&gt;
&lt;p&gt;one-line dataloaders for many public datasets: &lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;one liners to download and pre-process any of the number of datasets major public datasets (in 467 languages and dialects!) provided on the HuggingFace Datasets Hub. With a simple command like &lt;code&gt;squad_dataset = load_dataset(&amp;quot;squad&amp;quot;)&lt;&#x2F;code&gt;, get any of these datasets ready to use in a dataloader for training&#x2F;evaluating a ML model (Numpy&#x2F;Pandas&#x2F;PyTorch&#x2F;TensorFlow&#x2F;JAX),&lt;&#x2F;li&gt;
&lt;li&gt;efficient data pre-processing: simple, fast and reproducible data pre-processing for the above public datasets as well as your own local datasets in CSV&#x2F;JSON&#x2F;text. With simple commands like &lt;code&gt;tokenized_dataset = dataset.map(tokenize_example)&lt;&#x2F;code&gt;, efficiently prepare the dataset for inspection and ML model evaluation and training.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Language Technology Platform</title>
		<published>2021-08-28T11:35:41.496+00:00</published>
		<updated>2021-08-28T11:35:41.496+00:00</updated>
		<link href="https://resume.alongwy.top/projects/language-technology-platform/" type="text/html"/>
		<id>https://resume.alongwy.top/projects/language-technology-platform/</id>
		<content type="html">&lt;h3 id=&quot;intro&quot;&gt;Intro&lt;&#x2F;h3&gt;
&lt;p&gt;An open-source neural language technology platform supporting six fundamental Chinese NLP tasks:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;lexical analysis (Chinese word segmentation, part-of-speech tagging, and named entity recognition)&lt;&#x2F;li&gt;
&lt;li&gt;syntactic parsing (dependency parsing)&lt;&#x2F;li&gt;
&lt;li&gt;semantic parsing (semantic dependency parsing and semantic role labeling). &lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;quickstart&quot;&gt;Quickstart&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;python&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;from ltp import LTP

ltp = LTP()  # ÈªòËÆ§Âä†ËΩΩ Small Ê®°Âûã
seg, hidden = ltp.seg([&quot;‰ªñÂè´Ê±§ÂßÜÂéªÊãøÂ§ñË°£„ÄÇ&quot;])
pos = ltp.pos(hidden)
ner = ltp.ner(hidden)
srl = ltp.srl(hidden)
dep = ltp.dep(hidden)
sdp = ltp.sdp(hidden)
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;performance&quot;&gt;Performance&lt;&#x2F;h3&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot;&gt;Model&lt;&#x2F;th&gt;&lt;th align=&quot;center&quot;&gt;CWS&lt;&#x2F;th&gt;&lt;th align=&quot;center&quot;&gt;POS&lt;&#x2F;th&gt;&lt;th align=&quot;center&quot;&gt;NER&lt;&#x2F;th&gt;&lt;th align=&quot;center&quot;&gt;SRL&lt;&#x2F;th&gt;&lt;th align=&quot;center&quot;&gt;DEP&lt;&#x2F;th&gt;&lt;th align=&quot;center&quot;&gt;SDP&lt;&#x2F;th&gt;&lt;th align=&quot;center&quot;&gt;Speed(Sents&#x2F;S)&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;LTP 4.0 (Base)&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;98.70&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;98.50&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;95.4&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;80.60&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;89.50&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;75.20&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;39.12&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;LTP 4.0 (Base1)&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;99.22&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;98.73&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;96.39&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;79.28&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;89.57&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;76.57&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;--.--&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;LTP 4.0 (Base2)&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;99.18&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;98.69&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;95.97&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;79.49&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;90.19&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;76.62&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;--.--&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;LTP 4.0 (Small)&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;98.40&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;98.20&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;94.30&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;78.40&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;88.30&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;74.70&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;43.13&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;LTP 4.0 (Tiny)&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;96.80&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;97.10&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;91.60&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;70.90&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;83.80&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;70.10&lt;&#x2F;td&gt;&lt;td align=&quot;center&quot;&gt;53.22&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;h3 id=&quot;cite&quot;&gt;Cite&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;latex&quot; class=&quot;language-latex &quot;&gt;&lt;code class=&quot;language-latex&quot; data-lang=&quot;latex&quot;&gt;@article{che2020n,
  title={N-LTP: A Open-source Neural Chinese Language Technology Platform with Pretrained Models},
  author={Che, Wanxiang and Feng, Yunlong and Qin, Libo and Liu, Ting},
  journal={arXiv preprint arXiv:2009.11616},
  year={2020}
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>HIT-SCIR at MRP 2020: Transition-based Parser and Iterative Inference Parser</title>
		<published>2020-09-01T11:00:06.142+00:00</published>
		<updated>2020-09-01T11:00:06.142+00:00</updated>
		<link href="https://resume.alongwy.top/publications/hit-scir-at-mrp-2020-transition-based-parser-and-iterative-inference-parser/" type="text/html"/>
		<id>https://resume.alongwy.top/publications/hit-scir-at-mrp-2020-transition-based-parser-and-iterative-inference-parser/</id>
		<content type="html">&lt;p&gt;This paper describes our submission system (HIT-SCIR) for the CoNLL 2020 shared task: Cross-Framework and Cross-Lingual Meaning Representation Parsing. &lt;&#x2F;p&gt;
&lt;p&gt;The task includes five frameworks for graph-based meaning representations, i.e., UCCA, EDS, PTG, AMR, and DRG. &lt;&#x2F;p&gt;
&lt;p&gt;Our solution consists of two sub-systems: 
+ transition-based parser for Flavor (1) frameworks (UCCA, EDS, PTG)
+ iterative inference parser for Flavor (2) frameworks (DRG, AMR). &lt;&#x2F;p&gt;
&lt;p&gt;In the final evaluation, our system is ranked 3rd among the seven team both in Cross-Framework Track and Cross-Lingual Track, with the macro-averaged MRP F1 score of 0.81&#x2F;0.69.&lt;&#x2F;p&gt;
</content>
	</entry>
</feed>
